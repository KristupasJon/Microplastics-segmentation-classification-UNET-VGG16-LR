{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CZV52GGJxns"
      },
      "source": [
        "# Experimental code used for microplastic segmentation and classification with U-Net, VGG16, and LR.\n",
        "Work done by: Kristupas (https://github.com/KristupasJon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK8TTmN2itKF"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IndLtCjDWQHs",
        "outputId": "fcae3598-ebaf-4613-f027-7a91184a058d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkqjncH22KGI"
      },
      "source": [
        "Initiate imports, file paths, and other configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5JDMSUhsh8a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, jaccard_score, f1_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "IMG_CHANNELS = 3\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 80\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "IMAGES_DIR = '/content/drive/MyDrive/bachelors/dataset/images'\n",
        "MASKS_DIR = '/content/drive/MyDrive/bachelors/dataset/masks'\n",
        "CSV_LABELS = '/content/drive/MyDrive/bachelors/dataset/manual_labels.csv'\n",
        "SEG_OUTPUT_DIR = '/content/drive/MyDrive/bachelors/dataset/segmented_masks'\n",
        "VAL_CSV_LABELS = '/content/drive/MyDrive/bachelors/dataset/val_labels.csv'\n",
        "\n",
        "def load_labels(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df['label_idx'] = df['class_name'].map({'oval':0, 'string':1, 'other':2})\n",
        "    return df\n",
        "\n",
        "labels_df = load_labels(CSV_LABELS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kEC54EK181J"
      },
      "source": [
        "Define U-Net Segmentation Model. Prepare validation and training splits from images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-YqpHpGzLWo"
      },
      "outputs": [],
      "source": [
        "def conv_block(inputs, filters):\n",
        "    x = layers.Conv2D(filters, 3, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, filters):\n",
        "    x = conv_block(inputs, filters)\n",
        "    p = layers.MaxPooling2D()(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip, filters):\n",
        "    x = layers.Conv2DTranspose(filters, 2, strides=2, padding='same')(inputs)\n",
        "    x = layers.Concatenate()([x, skip])\n",
        "    return conv_block(x, filters)\n",
        "\n",
        "def build_unet(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n",
        "    i = layers.Input(shape)\n",
        "    s1, p1 = encoder_block(i, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "    b = conv_block(p4, 1024)\n",
        "    d1 = decoder_block(b, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "    o = layers.Conv2D(1, 1, activation='sigmoid')(d4)\n",
        "    return Model(i, o)\n",
        "\n",
        "def load_image_mask_pair(image_path, mask_path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image).astype(np.float32) / 255.0\n",
        "\n",
        "    mask = load_img(mask_path, color_mode='grayscale', target_size=target_size)\n",
        "    mask = img_to_array(mask).astype(np.float32) / 255.0\n",
        "    mask = np.where(mask > 0.5, 1.0, 0.0)\n",
        "    return image, mask\n",
        "\n",
        "def data_generator(image_paths, mask_paths, batch_size=BATCH_SIZE):\n",
        "    idxs = np.arange(len(image_paths))\n",
        "    while True:\n",
        "        np.random.shuffle(idxs)\n",
        "        for start in range(0, len(idxs), batch_size):\n",
        "            batch_idxs = idxs[start:start+batch_size]\n",
        "            imgs, msks = [], []\n",
        "            for i in batch_idxs:\n",
        "                img, msk = load_image_mask_pair(image_paths[i], mask_paths[i])\n",
        "                imgs.append(img); msks.append(msk)\n",
        "            yield np.stack(imgs, axis=0), np.stack(msks, axis=0)\n",
        "\n",
        "def augment(image, mask):\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        mask  = tf.image.flip_left_right(mask)\n",
        "\n",
        "    k = tf.random.uniform((), minval=0, maxval=4, dtype=tf.int32)\n",
        "    image = tf.image.rot90(image, k)\n",
        "    mask  = tf.image.rot90(mask,  k)\n",
        "\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    return image, mask\n",
        "\n",
        "img_files = set(os.listdir(IMAGES_DIR))\n",
        "mask_files = set(os.listdir(MASKS_DIR))\n",
        "common = sorted(img_files.intersection(mask_files))\n",
        "all_img_paths = [os.path.join(IMAGES_DIR, f) for f in common]\n",
        "all_mask_paths = [os.path.join(MASKS_DIR, f) for f in common]\n",
        "\n",
        "train_imgs, val_imgs, train_msks, val_msks = train_test_split(all_img_paths, all_mask_paths, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4LX5HUC4a5t"
      },
      "source": [
        "Initiate and compile the model. Prepare the model for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDE8W5zfbGQE"
      },
      "outputs": [],
      "source": [
        "accuracy = tf.keras.metrics.BinaryAccuracy(name='Tikslumas')\n",
        "precision = tf.keras.metrics.Precision(name='Preciziškumas')\n",
        "recall    = tf.keras.metrics.Recall(name='Atkūrimas')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kievPsk42-r4"
      },
      "outputs": [],
      "source": [
        "unet = build_unet()\n",
        "\n",
        "unet.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[accuracy, precision, recall]\n",
        ")\n",
        "\n",
        "train_gen = data_generator(train_imgs, train_msks)\n",
        "val_gen = data_generator(val_imgs, val_msks)\n",
        "steps = len(train_imgs)//BATCH_SIZE\n",
        "vsteps = len(val_imgs)//BATCH_SIZE\n",
        "callbacks = [ModelCheckpoint(f'unet{EPOCHS}.h5', save_best_only=True), EarlyStopping(patience=20, restore_best_weights=True)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibYlUZSQ4glr"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fphE3RuOc2cM"
      },
      "outputs": [],
      "source": [
        "history = unet.fit(train_gen, steps_per_epoch=steps, validation_data=val_gen, validation_steps=vsteps, epochs=EPOCHS, callbacks=callbacks)\n",
        "\n",
        "unet.save(f'unet_model_{EPOCHS}.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQAAGV8xamBQ"
      },
      "source": [
        "Plot metrics during segmentation model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWqbQ6HSalJk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def plot_train_metrics_separate(history, metrics_other, metric_acc='accuracy'):\n",
        "    epochs = range(1, len(history.history[metric_acc]) + 1)\n",
        "    font_kwargs = dict(fontsize=12, fontweight='light')\n",
        "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.plot(\n",
        "        epochs,\n",
        "        history.history[metric_acc],\n",
        "        label=metric_acc,\n",
        "        linewidth=1.0,\n",
        "        color=colors[0]\n",
        "    )\n",
        "    plt.title(\"Tikslumas kas treniravimo metu\")\n",
        "    plt.xlabel(\"Epocha\")\n",
        "    plt.ylabel(\"Tikslumas\")\n",
        "    plt.xticks(epochs)\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc=\"lower right\", frameon=False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    for idx, m in enumerate(metrics_other):\n",
        "        plt.plot(\n",
        "            epochs,\n",
        "            history.history[m],\n",
        "            label=m,\n",
        "            linewidth=1.0,\n",
        "            color=colors[idx + 1]\n",
        "        )\n",
        "    plt.title(\"Preciziškumas ir Atkūrimas treniravimo metu\")\n",
        "    plt.xlabel(\"Epocha\")\n",
        "    plt.ylabel(\"Vertė\", **font_kwargs)\n",
        "    plt.xticks(epochs, **font_kwargs)\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc=\"best\", frameon=False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "metrics_to_plot = ['Preciziškumas', 'Atkūrimas']\n",
        "plot_train_metrics_separate(history, metrics_to_plot, metric_acc='Tikslumas')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZpwTWC8y3cx"
      },
      "source": [
        "Load model weights to skip training if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIgiuYIopm7m"
      },
      "outputs": [],
      "source": [
        "#unet.load_weights('/content/drive/MyDrive/bachelors/unet.h5')\n",
        "unet.load_weights('/content/drive/MyDrive/bachelors/unet_model_60.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqa_zmpF0M7f"
      },
      "source": [
        "U-net model segmentation evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xZzMkNH0MXi"
      },
      "outputs": [],
      "source": [
        "def evaluate_segmentation_model(model, image_paths, mask_paths, batch_size=8, steps=None, threshold=0.5):\n",
        "    n = len(image_paths)\n",
        "    if steps is None:\n",
        "        steps = int(np.ceil(n / batch_size))\n",
        "\n",
        "\n",
        "    def _gen(paths_img, paths_msk, batch_size):\n",
        "        idxs = np.arange(len(paths_img))\n",
        "        for start in range(0, len(idxs), batch_size):\n",
        "            batch = idxs[start:start+batch_size]\n",
        "            imgs, msks = [], []\n",
        "            for i in batch:\n",
        "                img, msk = load_image_mask_pair(paths_img[i], paths_msk[i])\n",
        "                imgs.append(img); msks.append(msk)\n",
        "            yield np.stack(imgs,0), np.stack(msks,0)\n",
        "\n",
        "    y_true_all = []\n",
        "    y_score_all = []\n",
        "\n",
        "    gen = _gen(image_paths, mask_paths, batch_size)\n",
        "    for _ in range(steps):\n",
        "        imgs, msks = next(gen)\n",
        "        preds = model.predict(imgs)\n",
        "\n",
        "        y_true_all.append(msks.reshape(-1))\n",
        "        y_score_all.append(preds.reshape(-1))\n",
        "\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_score = np.concatenate(y_score_all)\n",
        "\n",
        "    y_pred = (y_score >= threshold).astype(np.uint8)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    jaccard = jaccard_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy':  accuracy,\n",
        "        'precision': precision,\n",
        "        'recall':    recall,\n",
        "        'jaccard':   jaccard,\n",
        "        'f1_score':  f1\n",
        "    }\n",
        "    counts = {\n",
        "        'TP': tp,\n",
        "        'TN': tn,\n",
        "        'FP': fp,\n",
        "        'FN': fn\n",
        "    }\n",
        "    raw = {\n",
        "        'y_true':  y_true,\n",
        "        'y_score': y_score,\n",
        "        'y_pred':  y_pred\n",
        "    }\n",
        "\n",
        "    print(f\"Accuracy : {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall   : {recall:.4f}\")\n",
        "    print(f\"F1 Score : {f1:.4f}\")\n",
        "    print(f\"Jaccard  : {jaccard:.4f}\")\n",
        "    print(f\"TP={tp}, TN={tn}, FP={fp}, FN={fn}\")\n",
        "\n",
        "    return metrics, counts, raw\n",
        "\n",
        "metrics, counts, raw = evaluate_segmentation_model(\n",
        "    model=unet,\n",
        "    image_paths=val_imgs,\n",
        "    mask_paths=val_msks,\n",
        "    batch_size=8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKMUyhdJ3Gte"
      },
      "source": [
        "Segment images at random for verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45tvG5IBh16n"
      },
      "outputs": [],
      "source": [
        "def show_predictions(model, image_paths, mask_paths, num_samples=3):\n",
        "    indices = random.sample(range(len(image_paths)), num_samples)\n",
        "\n",
        "    plt.figure(figsize=(15, num_samples * 3))\n",
        "    for i, idx in enumerate(indices):\n",
        "        image, mask = load_image_mask_pair(image_paths[idx], mask_paths[idx])\n",
        "        pred_mask = model.predict(np.expand_dims(image, axis=0))[0]\n",
        "\n",
        "        pred_mask_bin = (pred_mask > 0.5).astype(np.float32)\n",
        "\n",
        "        plt.subplot(num_samples, 3, i * 3 + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"Vaizdas\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num_samples, 3, i * 3 + 2)\n",
        "        plt.imshow(mask.squeeze(), cmap='gray')\n",
        "        plt.title(\"Tikroji kaukė\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(num_samples, 3, i * 3 + 3)\n",
        "        plt.imshow(pred_mask_bin.squeeze(), cmap='gray')\n",
        "        plt.title(\"Spėjama kaukė\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_predictions(unet, val_imgs, val_msks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1q1mNvl3Rvt"
      },
      "source": [
        "Process and save all segmented masks (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN6CbO1Nmzlw"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img = img_to_array(img).astype(np.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def segment_and_save(model, image_paths, output_dir, target_size=(IMG_HEIGHT, IMG_WIDTH), threshold=0.5):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = load_and_preprocess_image(img_path, target_size=target_size)\n",
        "\n",
        "        pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "\n",
        "        bin_mask = (pred > threshold).astype(np.uint8) * 255\n",
        "\n",
        "        pil_mask = array_to_img(bin_mask, scale=False)\n",
        "\n",
        "        base = os.path.basename(img_path)\n",
        "        name, _ = os.path.splitext(base)\n",
        "        out_path = os.path.join(output_dir, f\"{name}.jpg\")\n",
        "\n",
        "        pil_mask.save(out_path)\n",
        "\n",
        "image_paths = [\n",
        "    os.path.join(IMAGES_DIR, fname)\n",
        "    for fname in os.listdir(IMAGES_DIR)\n",
        "    if fname.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "]\n",
        "\n",
        "segment_and_save(unet, image_paths, SEG_OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqPdyw1v3cuI"
      },
      "source": [
        "Feature extraction with VGG16 from segmented masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk4AqUbzdygs"
      },
      "outputs": [],
      "source": [
        "def extract_patches_and_features(unet_model, images_dir, labels_df, fe):\n",
        "    feature_extractor = fe\n",
        "    features, labels, patch_meta = [], [], []\n",
        "\n",
        "    for fname in os.listdir(images_dir):\n",
        "        img_path = os.path.join(images_dir, fname)\n",
        "        mask = unet_model.predict(np.expand_dims(load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH)), axis=0)/255.0)[0,...,0]\n",
        "        mask_bin = (mask>0.5).astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(mask_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        orig = img_to_array(load_img(img_path))\n",
        "\n",
        "        for cnt in contours:\n",
        "            x,y,w,h = cv2.boundingRect(cnt)\n",
        "            crop = orig[y:y+h, x:x+w]\n",
        "            crop_resized = tf.image.resize(crop, [IMG_HEIGHT, IMG_WIDTH]).numpy()\n",
        "            proc = preprocess_input(np.expand_dims(crop_resized, axis=0))\n",
        "            feat = feature_extractor.predict(proc).flatten()\n",
        "            features.append(feat)\n",
        "            row = labels_df[labels_df['filename']==fname]\n",
        "            labels.append(row['label_idx'].values[0] if not row.empty else -1)\n",
        "            patch_meta.append((fname, x, y, w, h))\n",
        "\n",
        "    if not features:\n",
        "        raise ValueError(\"No patches detected. Check your segmentation masks or input images.\")\n",
        "    return np.vstack(features), np.array(labels), patch_meta\n",
        "\n",
        "feature_extractor = VGG16(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "features, labels_arr, patch_meta = extract_patches_and_features(unet, IMAGES_DIR, labels_df, feature_extractor)\n",
        "\n",
        "def assign_pseudo_labels(features, labels_arr, n_clusters=3):\n",
        "    if features.shape[0] < n_clusters:\n",
        "        raise ValueError(f\"Insufficient samples ({features.shape[0]}) for {n_clusters}-cluster KMeans.\")\n",
        "    km = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    clusters = km.fit_predict(features)\n",
        "    mapping = {}\n",
        "    for c in range(n_clusters):\n",
        "        idx = np.where((clusters==c)&(labels_arr>=0))[0]\n",
        "        mapping[c] = np.bincount(labels_arr[idx]).argmax() if len(idx)>0 else 0\n",
        "    return np.array([mapping[c] if labels_arr[i]<0 else labels_arr[i]\n",
        "                     for i, c in enumerate(clusters)])\n",
        "\n",
        "\n",
        "pseudo_labels = assign_pseudo_labels(features, labels_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6fz-n-W0o98"
      },
      "source": [
        "Save feature data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-l6s47YrFCz"
      },
      "outputs": [],
      "source": [
        "def save_features(features, labels, patch_meta, filename):\n",
        "    dtype = [('filename', 'U255'), ('x', int), ('y', int), ('w', int), ('h', int)]\n",
        "    patch_meta_array = np.array(patch_meta, dtype=dtype)\n",
        "\n",
        "    np.savez_compressed(\n",
        "        filename,\n",
        "        features=features,\n",
        "        labels=labels,\n",
        "        patch_meta=patch_meta_array\n",
        "    )\n",
        "\n",
        "save_features(features, labels_arr, patch_meta, 'extracted_features.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_T9mnlD1C7N"
      },
      "source": [
        "Load feature data to avoid extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Prl8el8g1GX5"
      },
      "outputs": [],
      "source": [
        "def load_features(filename):\n",
        "    data = np.load(filename)\n",
        "    patch_meta = [\n",
        "        (row['filename'], row['x'], row['y'], row['w'], row['h'])\n",
        "        for row in data['patch_meta']\n",
        "    ]\n",
        "    return data['features'], data['labels'], patch_meta\n",
        "\n",
        "def assign_pseudo_labels(features, labels_arr, n_clusters=3):\n",
        "    if features.shape[0] < n_clusters:\n",
        "        raise ValueError(f\"Insufficient samples ({features.shape[0]}) for {n_clusters}-cluster KMeans.\")\n",
        "    km = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    clusters = km.fit_predict(features)\n",
        "    mapping = {}\n",
        "    for c in range(n_clusters):\n",
        "        idx = np.where((clusters==c)&(labels_arr>=0))[0]\n",
        "        mapping[c] = np.bincount(labels_arr[idx]).argmax() if len(idx)>0 else 0\n",
        "    return np.array([mapping[c] if labels_arr[i]<0 else labels_arr[i]\n",
        "                     for i, c in enumerate(clusters)])\n",
        "\n",
        "\n",
        "features, labels, patch_meta = [], [], []\n",
        "features, labels_arr, patch_meta = load_features('extracted_features.npz')\n",
        "pseudo_labels = assign_pseudo_labels(features, labels_arr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQNQBhxX9LQn"
      },
      "source": [
        "Find the best hyperparameters for the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVbYSwsJ9K2-"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pagrindinis_clf = LogisticRegression(penalty='l2',multi_class='multinomial',class_weight='balanced',max_iter=10000,random_state=42)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'solver': ['lbfgs', 'sag', 'saga', 'newton-cg'],\n",
        "    'C':      [0.01, 0.1, 1, 10],\n",
        "}\n",
        "\n",
        "tinklelis = GridSearchCV(\n",
        "    estimator=pagrindinis_clf,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "tinklelis.fit(features, pseudo_labels)\n",
        "\n",
        "geriausias = tinklelis.best_estimator_\n",
        "print(f\"Geriausias CV tikslumas: {tinklelis.best_score_}\")\n",
        "print(f\"Geriausi parametrai: {tinklelis.best_params_}\")\n",
        "\n",
        "iteracijos = None\n",
        "if hasattr(geriausias, 'n_iter_'):\n",
        "    it = geriausias.n_iter_\n",
        "    iteracijos = it if isinstance(it, int) else it[0]\n",
        "print(f\"Iteracijų skaičius: {iteracijos}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq3zob7v5aaX"
      },
      "source": [
        "Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN__rymcvJv4"
      },
      "outputs": [],
      "source": [
        "labels = labels_arr[labels_arr >= 0]\n",
        "classes = np.unique(labels)\n",
        "\n",
        "weights = compute_class_weight(class_weight='balanced',classes=classes,y=labels)\n",
        "\n",
        "class_weight = dict(zip(classes, weights))\n",
        "\n",
        "#clf = LogisticRegression(class_weight=class_weight, max_iter=100)\n",
        "\n",
        "clf = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C= 1,\n",
        "    solver='saga',\n",
        "    multi_class='multinomial',\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "clf.fit(features, pseudo_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SUfXWFs1mEt"
      },
      "source": [
        "Evaluate classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfs1NI0EGB0B"
      },
      "outputs": [],
      "source": [
        "def evaluate_vgg_classifier_with_csv(clf, features, patch_meta, val_csv_path, class_map=None):\n",
        "    df = pd.read_csv(val_csv_path)\n",
        "    if class_map is None:\n",
        "        class_map = {'oval':0, 'string':1, 'other':2}\n",
        "    df['label_idx'] = df['class_name'].map(class_map)\n",
        "    true_label_lookup = dict(zip(df['filename'], df['label_idx']))\n",
        "\n",
        "    y_true = []\n",
        "    X_feats = []\n",
        "    for idx, (fname, x, y, w, h) in enumerate(patch_meta):\n",
        "        if fname in true_label_lookup:\n",
        "            y_true.append(true_label_lookup[fname])\n",
        "            X_feats.append(features[idx])\n",
        "\n",
        "    if len(y_true) == 0:\n",
        "        raise ValueError(f\"No patches found in CSV {val_csv_path}\")\n",
        "\n",
        "    X = np.vstack(X_feats)\n",
        "    y_true = np.array(y_true)\n",
        "\n",
        "    y_pred = clf.predict(X)\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    report = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=list(class_map.keys()),\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    total = cm.sum()\n",
        "    class_accuracies = {}\n",
        "    labels = list(class_map.keys())\n",
        "    for i, label in enumerate(labels):\n",
        "        TP = cm[i, i]\n",
        "        FP = cm[:, i].sum() - TP\n",
        "        FN = cm[i, :].sum() - TP\n",
        "        TN = total - TP - FP - FN\n",
        "        class_accuracies[label] = (TP + TN) / total\n",
        "\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall   : {rec:.4f}\")\n",
        "    for label, a in class_accuracies.items():\n",
        "        print(f\"Accuracy of {label:6s}: {a:.4f}\")\n",
        "    print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "    print(f\"\\nClassification Report:\\n{report}\")\n",
        "\n",
        "evaluate_vgg_classifier_with_csv(\n",
        "    clf=clf,\n",
        "    features=features,\n",
        "    patch_meta=patch_meta,\n",
        "    val_csv_path= VAL_CSV_LABELS\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpRmqD351omZ"
      },
      "source": [
        "Compile N samples of segmentations and classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9_7k47hlxzk"
      },
      "outputs": [],
      "source": [
        "def visualize_with_saved_features(unet_model, classifier, image_paths, mask_paths,features, patch_meta, num_samples=5):\n",
        "    class_names = ['ovalas', 'siulas', 'kita']\n",
        "\n",
        "    meta_to_idx = { meta: idx for idx, meta in enumerate(patch_meta) }\n",
        "\n",
        "    indices = random.sample(range(len(image_paths)), num_samples)\n",
        "    plt.figure(figsize=(18, num_samples * 4))\n",
        "\n",
        "    for i, img_idx in enumerate(indices):\n",
        "        img_path = image_paths[img_idx]\n",
        "        msk_path = mask_paths[img_idx]\n",
        "\n",
        "        image, true_mask = load_image_mask_pair(img_path, msk_path)\n",
        "        disp = (image * 255).astype(np.uint8).copy()\n",
        "\n",
        "        pred_mask = unet_model.predict(np.expand_dims(image, 0))[0, ..., 0]\n",
        "        bin_mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "        contours, _ = cv2.findContours(bin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for cnt in contours:\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            key = (os.path.basename(img_path), x, y, w, h)\n",
        "            if key not in meta_to_idx:\n",
        "                continue\n",
        "\n",
        "            feat_idx = meta_to_idx[key]\n",
        "            feat_vec = features[feat_idx]\n",
        "            pred_class = classifier.predict([feat_vec])[0]\n",
        "\n",
        "            cv2.rectangle(disp, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(disp, class_names[pred_class], (x, y - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        plt.subplot(num_samples, 4, i * 4 + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"Vaizdas\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(num_samples, 4, i * 4 + 2)\n",
        "        plt.imshow(true_mask.squeeze(), cmap='gray')\n",
        "        plt.title(\"Tikroji kaukė\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(num_samples, 4, i * 4 + 3)\n",
        "        plt.imshow(bin_mask, cmap='gray');\n",
        "        plt.title(\"Spėjama kaukė\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(num_samples, 4, i * 4 + 4)\n",
        "        plt.imshow(disp)\n",
        "        plt.title(\"Klasifikacija\");plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "feature_extractor = VGG16(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "visualize_with_saved_features(unet, clf, val_imgs, val_msks, features, patch_meta, num_samples=81)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWsVoj5sAicp"
      },
      "source": [
        "Use single image for segmentation and classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AAlhQLWBxdV"
      },
      "outputs": [],
      "source": [
        "def visualize_single_image_with_saved_features(unet_model, classifier, images_dir, masks_dir, features, patch_meta, image_name):\n",
        "\n",
        "    class_names = ['oval', 'string', 'other']\n",
        "\n",
        "    meta_to_idx = { meta: idx for idx, meta in enumerate(patch_meta) }\n",
        "\n",
        "    img_path = os.path.join(images_dir, image_name)\n",
        "    msk_path = os.path.join(masks_dir,  image_name)\n",
        "    if not os.path.exists(img_path):\n",
        "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "    if not os.path.exists(msk_path):\n",
        "        raise FileNotFoundError(f\"Mask not found: {msk_path}\")\n",
        "\n",
        "    image, true_mask = load_image_mask_pair(img_path, msk_path)\n",
        "    disp = (image * 255).astype(np.uint8).copy()\n",
        "\n",
        "    pred_mask = unet_model.predict(np.expand_dims(image, 0))[0, ..., 0]\n",
        "    bin_mask  = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    contours, _ = cv2.findContours(bin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    for cnt in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        key = (image_name, x, y, w, h)\n",
        "        if key not in meta_to_idx:\n",
        "            continue\n",
        "\n",
        "        feat_idx = meta_to_idx[key]\n",
        "        feat_vec  = features[feat_idx]\n",
        "        pred_cl   = classifier.predict([feat_vec])[0]\n",
        "\n",
        "        cv2.rectangle(disp, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(disp, class_names[pred_cl], (x, y - 5),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Vaizdas\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.imshow(true_mask.squeeze(), cmap='gray')\n",
        "    plt.title(\"Tikroji kaukė\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.imshow(bin_mask, cmap='gray')\n",
        "    plt.title(\"Segmentuota kaukė\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(disp)\n",
        "    plt.title(\"Klasifikacija\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_single_image_with_saved_features(\n",
        "    unet_model=unet,\n",
        "    classifier=clf,\n",
        "    images_dir=IMAGES_DIR,\n",
        "    masks_dir=MASKS_DIR,\n",
        "    features=features,\n",
        "    patch_meta=patch_meta,\n",
        "    image_name='20211223110429.jpg'\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
